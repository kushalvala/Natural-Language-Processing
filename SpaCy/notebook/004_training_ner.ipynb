{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why updating the model?\n",
    "1. Better results on your specific domain\n",
    "2. Learn classification schemes specifically for your problem\n",
    "3. Essential for text classification\n",
    "4. Very useful for named entity recognition\n",
    "5. Less critical for part-of-speech tagging and dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Statistical models make predictions based on the examples they were trained on.\n",
    "You can usually make the model more accurate by showing it examples from your domain.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How training works\n",
    "\n",
    "1. Initialize the model weights randomly with nlp.begin_training\n",
    "2. Predict a few examples with the current weights by calling nlp.update\n",
    "3. Compare prediction with true labels\n",
    "4. Calculate how to change weights to improve predictions\n",
    "5. Update weights slightly\n",
    "6. Go back to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data are the examples we want to update the model with.\n",
    "The text should be a sentence, paragraph or longer document. For the best results, it should be similar to what the model will see at runtime. \\\n",
    "The label is what we want the model to predict. This can be a **text category, or an entity span and its type.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Entity Recognizer\n",
    "\n",
    "The entity recognizer takes a document and predicts phrases and their labels. This means that the training data needs to include texts, the entities they contain, and the entity labels. \\\n",
    "The easiest way to do this is to show the model a text and a list of character offsets. For example, \"iPhone X\" is a gadget, starts at character 0 and ends at character 8. \\\n",
    "It's also very important for the model to learn words that aren't entities.\n",
    "In this case, the list of span annotations will be empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data tells the model what we want it to predict. This could be texts and named entities we want to recognize, or tokens and their correct part-of-speech tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Training Data\n",
    "\n",
    "spaCy’s rule-based Matcher is a great way to quickly create training data for named entity models. A list of sentences is available as the variable TEXTS. You can print it the IPython shell to inspect it. We want to find all mentions of different iPhone models, so we can create training data to teach a model to recognize them as 'GADGET'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "with open(\"iphone.json\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
    "pattern1 = [{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "\n",
    "# Token whose lowercase form matches 'iphone' and an optional digit\n",
    "pattern2 = [{\"LOWER\": \"iphone\"}, {\"IS_DIGIT\": True, \"OP\": \"?\"}]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add(\"GADGET\", None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: How to preorder the iPhone X\n",
      "[(20, 28, 'GADGET'), (20, 26, 'GADGET')]\n",
      "\n",
      "document: iPhone X is coming\n",
      "[(0, 8, 'GADGET'), (0, 6, 'GADGET')]\n",
      "\n",
      "document: Should I pay $1,000 for the iPhone X?\n",
      "[(28, 36, 'GADGET'), (28, 34, 'GADGET')]\n",
      "\n",
      "document: The iPhone 8 reviews are here\n",
      "[(4, 12, 'GADGET')]\n",
      "\n",
      "document: Your iPhone goes up to 11 today\n",
      "[(5, 11, 'GADGET')]\n",
      "\n",
      "document: I need a new phone! Any tips?\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    print('document: '+ doc.text)\n",
    "    \n",
    "    # Match on a doc, and create a list of matched span\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    \n",
    "    # Get the start,end and entity label for matchs\n",
    "    entities = [(span.start_char, span.end_char, \"GADGET\") for span in spans]\n",
    "    \n",
    "    print(entities)\n",
    "    \n",
    "    # Format the matches\n",
    "    \n",
    "    training_example = (doc.text, {\"entities\": entities})\n",
    "    \n",
    "    # Append the training example\n",
    "    TRAINING_DATA.append(training_example)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET'), (20, 26, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 8, 'GADGET'), (0, 6, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET'), (28, 34, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': [(4, 12, 'GADGET')]})\n",
      "('Your iPhone goes up to 11 today', {'entities': [(5, 11, 'GADGET')]})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "print(*TRAINING_DATA, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you’ll prepare a spaCy pipeline to train the entity recognizer to recognize 'GADGET' entities in a text – for example, “iPhone X”.\n",
    "1. Create a blank 'en' model, for example using the spacy.blank method.\n",
    "2. Create a new entity recognizer using nlp.create_pipe and add it to the pipeline.\n",
    "3. Add the new label 'GADGET' to the entity recognizer using the add_label method on the pipeline component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2000001669\n",
      "22.8406054974\n",
      "32.1119040251\n",
      "7.3094803691\n",
      "14.8997436762\n",
      "19.4442685843\n",
      "2.8595558442\n",
      "4.2886928841\n",
      "7.3126856391\n",
      "2.4475634160\n",
      "4.2746486550\n",
      "4.8367750854\n",
      "0.7174652632\n",
      "1.5059775252\n",
      "2.1358702074\n",
      "0.0545349050\n",
      "0.9280381885\n",
      "0.9855622620\n",
      "0.0009599526\n",
      "0.0033613277\n",
      "1.0005644007\n",
      "0.7024979204\n",
      "0.7025046145\n",
      "0.7025407334\n",
      "7.2759053467\n",
      "7.2759540292\n",
      "7.2759554727\n",
      "0.0000247821\n",
      "0.0000264150\n",
      "2.5797555731\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Create a blank 'en' model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create a new entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "# Add the label 'GADGET' to the entity recognizer\n",
    "ner.add_label(\"GADGET\")\n",
    "\n",
    "nlp.vocab.vectors.name = 'example'\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "for itn in range(10):\n",
    "    \n",
    "    # Shuffle the random examples:\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    \n",
    "    losses = {}\n",
    "    \n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size= 2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "        \n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "        print(\"{0:.10f}\".format(losses['ner']) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
