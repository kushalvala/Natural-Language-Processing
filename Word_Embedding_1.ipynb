{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embedding-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcSByhT-bEuL",
        "colab_type": "text"
      },
      "source": [
        "There are primarily two main classes of methods to generate *Word Embeddings*\n",
        "\n",
        "  * Frequency based methods\n",
        "  * Prediction based methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVG3TNDaaRx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S5J-dLVdRos",
        "colab_type": "text"
      },
      "source": [
        "#### Frequency Based Methods:\n",
        "  1. Count Vectors (Bag of Words)\n",
        "  2. Tf-IDF Vectors\n",
        "  3. Co-Occurrence Vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCj0x_NXe_jM",
        "colab_type": "text"
      },
      "source": [
        "Count Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMMOpEOYcICG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6431c346-8e71-45ae-f605-c15a578b8b0f"
      },
      "source": [
        "# Initalising the corpus\n",
        "corpus = ['This movie is very Scary and long',\n",
        "          'This movie is not scary and is slow',\n",
        "          'This movie is spooky and good'\n",
        "          ]\n",
        "\n",
        "# Defining the method to generate 1-gram BoW Tokens\n",
        "vectorizer = CountVectorizer(lowercase = True, ngram_range = (1,1))\n",
        "\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names())\n",
        "\n",
        "print(X.toarray())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'good', 'is', 'long', 'movie', 'not', 'scary', 'slow', 'spooky', 'this', 'very']\n",
            "[[1 0 1 1 1 0 1 0 0 1 1]\n",
            " [1 0 2 0 1 1 1 1 0 1 0]\n",
            " [1 1 1 0 1 0 0 0 1 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A49e5nstdM1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0983305a-ee9b-449a-fcc6-995cfd163be2"
      },
      "source": [
        "# bi-gram Bag Of Word Models\n",
        "\n",
        "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2), lowercase = True)\n",
        "X2 = vectorizer2.fit_transform(corpus)\n",
        "print(vectorizer2.get_feature_names())\n",
        "print(X2.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and good', 'and is', 'and long', 'is not', 'is slow', 'is spooky', 'is very', 'movie is', 'not scary', 'scary and', 'spooky and', 'this movie', 'very scary']\n",
            "[[0 0 1 0 0 0 1 1 0 1 0 1 1]\n",
            " [0 1 0 1 1 0 0 1 1 1 0 1 0]\n",
            " [1 0 0 0 0 1 0 1 0 0 1 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBiCaM0dfCp_",
        "colab_type": "text"
      },
      "source": [
        "Tf-IDF Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo9HnKMVeNBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a31978d6-fda4-463e-cb2f-94f04c24e1c2"
      },
      "source": [
        "corpus = ['This movie is very Scary and long',\n",
        "          'This movie is not scary and is slow',\n",
        "          'This movie is spooky and good'\n",
        "          ]\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase = True, ngram_range= (1,1))\n",
        "\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(tfidf_vectorizer.get_feature_names())\n",
        "\n",
        "print(X_tfidf.toarray())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'good', 'is', 'long', 'movie', 'not', 'scary', 'slow', 'spooky', 'this', 'very']\n",
            "[[0.29628336 0.         0.29628336 0.50165133 0.29628336 0.\n",
            "  0.38151877 0.         0.         0.29628336 0.50165133]\n",
            " [0.26359985 0.         0.5271997  0.         0.26359985 0.44631334\n",
            "  0.3394328  0.44631334 0.         0.26359985 0.        ]\n",
            " [0.32052772 0.54270061 0.32052772 0.         0.32052772 0.\n",
            "  0.         0.         0.54270061 0.32052772 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "920i7rJm4Qv8",
        "colab_type": "text"
      },
      "source": [
        "Co-Occurence Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miLruZmofbmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import bigrams\n",
        "import itertools\n",
        "import pandas as pd\n",
        " \n",
        " \n",
        "def generate_co_occurrence_matrix(corpus):\n",
        "\n",
        "    vocab = set(corpus)\n",
        "    vocab = list(vocab)\n",
        "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
        " \n",
        "    # Create bigrams from all words in corpus\n",
        "    bi_grams = list(bigrams(corpus))\n",
        " \n",
        "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
        "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
        " \n",
        "    # Initialise co-occurrence matrix\n",
        "    # co_occurrence_matrix[current][previous]\n",
        "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
        " \n",
        "    # Loop through the bigrams taking the current and previous word,\n",
        "    # and the number of occurrences of the bigram.\n",
        "    for bigram in bigram_freq:\n",
        "        current = bigram[0][1]\n",
        "        previous = bigram[0][0]\n",
        "        count = bigram[1]\n",
        "        pos_current = vocab_index[current]\n",
        "        pos_previous = vocab_index[previous]\n",
        "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
        "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
        " \n",
        "    # return the matrix and the index\n",
        "    return co_occurrence_matrix, vocab_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93zHBeI-7HKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [['Where', 'Python', 'is', 'used'],\n",
        "             ['What', 'is', 'Python' 'used', 'in'],\n",
        "             ['Why', 'Python', 'is', 'best'],\n",
        "             ['What', 'companies', 'use', 'Python']]\n",
        "\n",
        "data = list(itertools.chain.from_iterable(corpus))\n",
        "\n",
        "matrix, vocab_index = generate_co_occurrence_matrix(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-VKkWTR7ete",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "647e04de-a658-4bc7-e4da-9da3eae30c1e"
      },
      "source": [
        "matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [2., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn3DuxQm79LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.max_rows = 100\n",
        "pd.options.display.max_columns = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRqjFNYk73VQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "d8b5931d-3063-4e22-f3ae-95af7e81323f"
      },
      "source": [
        "data_matrix = pd.DataFrame(matrix, index=vocab_index,\n",
        "                             columns=vocab_index)\n",
        "print(data_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Python  companies   is  use  best  Pythonused  Where  What   in  \\\n",
            "Python      0.0     0.0        0.0  1.0  0.0   0.0         1.0    0.0   0.0   \n",
            "companies   0.0     0.0        0.0  0.0  0.0   0.0         0.0    1.0   0.0   \n",
            "is          2.0     0.0        0.0  0.0  0.0   0.0         0.0    1.0   0.0   \n",
            "use         0.0     1.0        0.0  0.0  0.0   0.0         0.0    0.0   0.0   \n",
            "best        0.0     0.0        1.0  0.0  0.0   0.0         0.0    0.0   0.0   \n",
            "Pythonused  0.0     0.0        1.0  0.0  0.0   0.0         0.0    0.0   0.0   \n",
            "Where       0.0     0.0        0.0  0.0  0.0   0.0         0.0    0.0   0.0   \n",
            "What        0.0     0.0        0.0  0.0  1.0   0.0         0.0    0.0   0.0   \n",
            "in          0.0     0.0        0.0  0.0  0.0   1.0         0.0    0.0   0.0   \n",
            "Why         0.0     0.0        0.0  0.0  0.0   0.0         0.0    0.0   1.0   \n",
            "used        0.0     0.0        1.0  0.0  0.0   0.0         0.0    0.0   0.0   \n",
            "\n",
            "            Why  used  \n",
            "Python      1.0  0.0   \n",
            "companies   0.0  0.0   \n",
            "is          0.0  0.0   \n",
            "use         0.0  0.0   \n",
            "best        0.0  0.0   \n",
            "Pythonused  0.0  0.0   \n",
            "Where       0.0  0.0   \n",
            "What        0.0  1.0   \n",
            "in          0.0  0.0   \n",
            "Why         0.0  0.0   \n",
            "used        0.0  0.0   \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}